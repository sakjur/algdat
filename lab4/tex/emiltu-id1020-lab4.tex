\documentclass[a4paper,11pt]{article}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[parfill]{parskip}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{enumitem}

\lstset{
  language=Java,
  basicstyle=\footnotesize\ttfamily,
  numbers=left,
  breaklines=true,
  frame=lr,
  captionpos=b,
  showstringspaces=false,
  escapeinside={@*}{*@}
}
\newcounter{counter}

\title{ID1020 Laboration 3}
\author{Emil Tullstedt}

\hyphenation{definition algo-rithm}

\begin{document}
\maketitle

\newpage

\tableofcontents

\newpage

\section{Trees}
\label{sec:trees}

\subsection{Graphs \textit{\&} Trees}

Following is an analysis of five directed graphs to determine if they fit into the definition of a tree\footnote{Doesn't contain any cycles \textit{\&} has one element from which every other element can be derived} or, if it isn't a tree, which cycles are contained within the graph.

\begin{enumerate}[label=\bfseries Graph \arabic*:]
\item $G_1$ is a tree with the root in 1
\item $G_2$ is a tree with the root in 1
\item $G_3$ has a cycle 6--2--1
\item $G_4$ is a tree with the root in 6
\item $G_5$ has a cycle 6--2--1--4
\end{enumerate}
\newpage
\subsection{Tree Traversal}

The tuples given below is five traversals of a tree which has it's root 4 which has the children 2 and 6. The children of 2 is 1 and 3 and the children of 6 is 5 and 7.

For the first four traversals, the instructions \textsc{Traverse}($l$), \textsc{Traverse}($r$) and \textsc{Visit}($v$) are utilized. These are parsed as if they were defined

\begin{description}[style=multiline,leftmargin=3cm]
\item[\textsc{Traverse}($l$)] If possible, move to the first child and execute an iteration of the algorithm on that child
\item[\textsc{Traverse}($r$)] Same as \textsc{Traverse}($l$) but for the second child
\item[\textsc{Visit}($v$)] Append the tuple with the current vector $v$
\end{description}

The final traversal (breadth-first) is defined in pseudocode using the definition of \textsc{Visit}($v$) given above. The breadth-first algorithm is parsed as if it begins with the left-most item on a row, appends it to the tuple and then continues from left to right on that row until it finds the right-most item, when it continues in the same manner on the next row.

The list below describes the different scenarios.

\begin{description}[style=multiline,leftmargin=6cm]
\item[Pre-order] \texttt{(4, 2, 1, 3, 6, 5, 7)}
\item[In-order (Ascending)] \texttt{(1, 2, 3, 4, 5, 6, 7)}
\item[In-order (Descending)] \texttt{(7, 6, 5, 4, 3, 2, 1)}
\item[Post-order] \texttt{(1, 3, 2, 5, 7, 6, 4)}
\item[Breadth-first] \texttt{(4, 2, 6, 1, 3, 5, 7)}
\end{description}
\newpage
\subsection{TreeSort}
\subsubsection{Time-complexity}
When analysing the algorithm for TreeSort given in task 2.3 one can quickly see that the task contains two loops that are running independently from each other. When splitting the algorithm into two parts, algorithm \ref{into_graph} and algorithm \ref{from_graph}, we can analyze them one by one instead of having to look at the whole picture at a time. The total time consumption will therefore be the sum of algorithm \ref{into_graph} and algorithm \ref{from_graph}.

\begin{algorithm}
\caption{Convert from list to graph}
\label{into_graph}

\begin{algorithmic}
\While{\textsc{Length}($l$) $> 0$}
\State $v\gets$\textsc{PopFirst}($l$)
\State \textsc{Add}($T$, $v$) // This takes $O(\log n)$
\EndWhile
\end{algorithmic}
\end{algorithm}

The first part of the algorithm, given in algorithm \ref{into_graph}, iterates once over every item in the list $l$ (which contains $n > 0$ items) and places them on the correct place within the tree which takes $O(\log n)$ for each item $v$ in $n$. As we run this over all $n$ objects, we get a total time complexity of $O(n \log n)$.

\begin{algorithm}
\caption{Convert from graph to sorted list}
\label{from_graph}

\begin{algorithmic}
\For{$v \in T$}
\State \textsc{Append}($l$, $v$)
\EndFor
\end{algorithmic}
\end{algorithm}

The second part of the algorithm, which is displayed in algorithm \ref{from_graph} uses the \textit{In-Order (asc)} from task 2.2 which visits all the nodes in an ascending order. This operation also has a big-oh of $O(n\log n)$ as it climbs the tree up to $\log n$ times for all the $n$ vertices.

Therefore, according to the fact that algorithm \ref{into_graph} and \ref{from_graph} is the total, we can conclude that the function in it's entirety must be defined by $$\textsc{TreeSort}(l) = O(n\log n) + O(n\log n) = O(n\log n)$$

As the tree is balanced on insertion, the input to algorithm \ref{from_graph} is the same no matter what permutation is inserted into algorithm \ref{into_graph} and thus the best-case will always be the same as worst-case, $O(n\log n)$.

$$\therefore \textit{Worst-case} = \textit{Best-case} = O(n\log n)$$

\subsubsection{Memory Complexity: Comparison with MergeSort}
To determine which of \textsc{MergeSort} and \textsc{TreeSort} that is the most memory efficent, here's the definition of a few sizes that are shared between the two algorithms

\begin{tabular}{|l|l|l|}
\hline
\textbf{Name} & \textbf{Size} & \textbf{Explanation}\\
\hline
$s_v$ & $j$ (probably 1--8B) & The size of each element in the list $l$\\
\hline
$s_{ref}$ & 8B & Size of a reference\\
\hline
$s_{oh}$ & 16B & Object overhead for each object \\
\hline
$|l|$ & $k$ & Number of elements in the list $l$\\
\hline
$s_{l}$ & $|l|(s_v + s_{ref} + s_{oh}) + s_{ref} + s_{oh}$ & Size of the entire linked list $l$\\
\hline
\end{tabular}

Beginning with \textsc{TreeSort} the tree nodes have the form (ref, $v$, ref) which means that each node is an object (thus having the object overhead of 16B) with two references (รก 8B, ergo 16B) and the vertice-content $v$ of undefined memory size.

This nets a total of $(32 + s_v)$B per node within the tree. The tree in it's entirety contains of $|l|$ nodes. As the tree is an abstract concept of multiple linked nodes, there is no object overhead on the heap for the tree.

The tree's complete size can therefore be described as $s_{tree} = |l|(32 + S_v)$ bytes. We also initialize a single linked list, which has the size of $s_{l} = |l|(s_v + 8 + 16) + 8 + 16 = |l|(s_v + 24) + 24$ bytes.

The entire heap size of \textsc{TreeSort} should therefore be $$s_{ts} = |l|(2*s_v + 56) + 24\ \textrm{bytes}$$

The \textsc{MergeSort} heap contains two arrays of size $|l|s_v + 24$B which nets to $$s_{ms} = 2|l|s_v + 48\ \textrm{bytes}$$

This means that \textsc{MergeSort} is slightly more memory efficient than the \textsc{TreeSort}. Calculating the difference between $s_{ts}$ and $s_{ms}$ gives us $$\Delta(s_{ts}, s_{ms}) = s_{ts} - s_{ms} = (|l|(2 * s_v + 56) + 24) - (2|l|s_v + 48) = 56|l| - 24\ \textrm{bytes}$$

\textit{A sidenote:} As \textsc{MergeSort} requires random element access to the elements in the list while \textsc{TreeSort} only assumes having access to the list in order, the \textsc{TreeSort} doesn't need consecutive memory areas available and can therefore be a better choice even in memory-limited areas.

\subsubsection{Stability}
\textsc{TreeSort} is stable as the duplicate values are returned in the order of insertion per the definition in the task.
\end{document}